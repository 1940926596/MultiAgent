{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e628ecc1",
   "metadata": {},
   "source": [
    "##  EODHD API 下载EODHD 新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe05dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import config as cfg\n",
    "from eodhd import APIClient\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c38d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the proxy URL and port\n",
    "proxy_url = 'http://127.0.0.1'\n",
    "proxy_port = '7890' # !!!please replace it with your own port\n",
    "\n",
    "# Set the http_proxy and https_proxy environment variables\n",
    "os.environ['http_proxy'] = f'{proxy_url}:{proxy_port}'\n",
    "os.environ['https_proxy'] = f'{proxy_url}:{proxy_port}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6666235",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '683974733bfcd4.56880792'\n",
    "api = APIClient(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44afbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import time\n",
    "\n",
    "# def get_all_financial_news(api_token, symbol, from_date, to_date, delay=1):\n",
    "#     all_news = []\n",
    "#     offset = 0\n",
    "#     limit = 100  # EODHD 限制最大为 100\n",
    "#     base_url = \"https://eodhistoricaldata.com/api/news\"\n",
    "\n",
    "#     while True:\n",
    "#         params = {\n",
    "#             \"api_token\": api_token,\n",
    "#             \"s\": symbol,\n",
    "#             \"from\": from_date,\n",
    "#             \"to\": to_date,\n",
    "#             \"offset\": offset,\n",
    "#             \"limit\": limit,\n",
    "#         }\n",
    "\n",
    "#         response = requests.get(base_url, params=params)\n",
    "#         data = response.json()\n",
    "\n",
    "#         if not data or len(data) == 0:\n",
    "#             break\n",
    "\n",
    "#         all_news.extend(data)\n",
    "\n",
    "#         print(f\"Fetched {len(data)} news, total so far: {len(all_news)}\")\n",
    "\n",
    "#         # 分页继续\n",
    "#         offset += limit\n",
    "\n",
    "#         # 避免触发请求限制（每秒1次即可）\n",
    "#         time.sleep(delay)\n",
    "\n",
    "#     return all_news\n",
    "\n",
    "\n",
    "# news_list = get_all_financial_news(\n",
    "#     api_token=api_key,\n",
    "#     symbol=\"AAPL.US\",\n",
    "#     from_date=\"2024-08-01\",\n",
    "#     to_date=\"2024-12-30\"\n",
    "# )\n",
    "\n",
    "# print(f\"共获取新闻 {len(news_list)} 条\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdbabfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:11:36] </span>Expecting value: line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> column <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>char <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>                                                  <a href=\"file:///data/postgraduates/2024/chenjiarui/anaconda3/envs/Qwen-Py310/lib/python3.10/site-packages/eodhd/APIs/BaseAPI.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">BaseAPI.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/postgraduates/2024/chenjiarui/anaconda3/envs/Qwen-Py310/lib/python3.10/site-packages/eodhd/APIs/BaseAPI.py#39\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:11:36]\u001b[0m\u001b[2;36m \u001b[0mExpecting value: line \u001b[1;36m1\u001b[0m column \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mchar \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                                  \u001b]8;id=82173;file:///data/postgraduates/2024/chenjiarui/anaconda3/envs/Qwen-Py310/lib/python3.10/site-packages/eodhd/APIs/BaseAPI.py\u001b\\\u001b[2mBaseAPI.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=739417;file:///data/postgraduates/2024/chenjiarui/anaconda3/envs/Qwen-Py310/lib/python3.10/site-packages/eodhd/APIs/BaseAPI.py#39\u001b\\\u001b[2m39\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span> Server Error: Internal Server Error for url:                                           <a href=\"file:///data/postgraduates/2024/chenjiarui/anaconda3/envs/Qwen-Py310/lib/python3.10/site-packages/eodhd/APIs/BaseAPI.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">BaseAPI.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/postgraduates/2024/chenjiarui/anaconda3/envs/Qwen-Py310/lib/python3.10/site-packages/eodhd/APIs/BaseAPI.py#52\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://eodhd.com/api/news/?api_token=683974733bfcd4.56880792&amp;fmt=json&amp;s=AAPL.US&amp;limit=10&amp;</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">from=2024-08-01&amp;to=2024-08-30</span>                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36m500\u001b[0m Server Error: Internal Server Error for url:                                           \u001b]8;id=636892;file:///data/postgraduates/2024/chenjiarui/anaconda3/envs/Qwen-Py310/lib/python3.10/site-packages/eodhd/APIs/BaseAPI.py\u001b\\\u001b[2mBaseAPI.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=489145;file:///data/postgraduates/2024/chenjiarui/anaconda3/envs/Qwen-Py310/lib/python3.10/site-packages/eodhd/APIs/BaseAPI.py#52\u001b\\\u001b[2m52\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[4;94mhttps://eodhd.com/api/news/?\u001b[0m\u001b[4;94mapi_token\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94m683974733bfcd4\u001b[0m\u001b[4;94m.56880792&\u001b[0m\u001b[4;94mfmt\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94mjson\u001b[0m\u001b[4;94m&\u001b[0m\u001b[4;94ms\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94mAAPL\u001b[0m\u001b[4;94m.US&\u001b[0m\u001b[4;94mlimit\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94m10\u001b[0m\u001b[4;94m&\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[4;94mfrom\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94m2024\u001b[0m\u001b[4;94m-08-01&\u001b[0m\u001b[4;94mto\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94m2024\u001b[0m\u001b[4;94m-08-30\u001b[0m                                                              \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resp = api.financial_news(s = \"AAPL.US\", from_date = '2024-08-01', to_date = '2024-08-30', limit = 10)\n",
    "df = pd.DataFrame(resp) # converting the json output into datframe\n",
    "df.tail()\n",
    "s = \"AAPL_US\"\n",
    "from_date = '2024-08-01'\n",
    "\n",
    "save_path=\"../../datasets/news\"\n",
    "df.to_csv(f\"{save_path}/{s}_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0b1adc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_text\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Apply the replacement function to the entire column\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(clean_text)\n",
      "File \u001b[0;32m~/anaconda3/envs/Qwen-Py310/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/Qwen-Py310/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content'"
     ]
    }
   ],
   "source": [
    "#funtion to clean the textual data\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "# Apply the replacement function to the entire column\n",
    "df['content'] = df['content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bdbd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\",\n",
    "                 openai_api_key = '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', \n",
    "                 temperature = 0)\n",
    "\n",
    "print(df['content'][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Identify the sentiment towards the Apple(AAPL) stocks from the news article , where the sentiment score should be from -10 to +10 where -10 being the most negative and +10 being the most positve , and 0 being neutral\n",
    "\n",
    "Also give the proper explanation for your answers and how would it effect the prices of different stocks\n",
    "\n",
    "Article : {statement}\n",
    "\"\"\"\n",
    "\n",
    "#forming prompt using Langchain PromptTemplate functionality\n",
    "prompt = PromptTemplate(template = template, input_variables = [\"statement\"])\n",
    "llm_chain = LLMChain(prompt = prompt, llm = llm)\n",
    "\n",
    "print(llm_chain.run(df['content'][13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc15c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(llm_chain.run(df['content'][13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to count the number of tokens\n",
    "def count_tokens(text):\n",
    "    tokens = text.split()  \n",
    "    return len(tokens)\n",
    "\n",
    "\"\"\"\n",
    "这个函数的作用是：将输入的文本字符串按空格拆分成单词（这里用的最简单的空格分割，实际上不是真正的“token”分词，但能做粗略估计）。\n",
    "然后返回分出来的“单词”数量，即文本长度的近似“token数”。\n",
    "\"\"\"\n",
    "\n",
    "# Applying the tokenization function to the DataFrame column\n",
    "df['TokenCount'] = df['content'].apply(count_tokens)\n",
    "\n",
    "\"\"\"\n",
    "对 df['content'] 每个文本调用 count_tokens，计算它的“token数”，存到新列 TokenCount。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Define a token count threshold (for example, keep rows with more than 2 tokens)\n",
    "token_count_threshold = 3500\n",
    "#这个阈值表示：只保留“token数”少于3500的文本行。\n",
    "\n",
    "\n",
    "# Create a new DataFrame by filtering based on the token count\n",
    "new_df = df[df['TokenCount'] < token_count_threshold]\n",
    "#选出满足条件的行，得到新 DataFrame new_df。\n",
    "\n",
    "\n",
    "# Drop the 'TokenCount' column from the new DataFrame if you don't need it\n",
    "new_df = new_df.drop('TokenCount', axis = 1)\n",
    "#除辅助列 TokenCount，避免干扰后续操作。\n",
    "\n",
    "\n",
    "# Resetting the index\n",
    "new_df = new_df.reset_index(drop = True)\n",
    "#因为之前筛选后索引可能不连续，调用 reset_index(drop=True) 让索引从0开始重新排列，且不保留旧索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_2 = \"\"\"\n",
    "Identify the sentiment towards the Apple(AAPL) stocks of the news article from -10 to +10 where -10 being the most negative and +10 being the most positve , and 0 being neutral\n",
    "\n",
    "GIVE ANSWER IN ONLY ONE WORD AND THAT SHOULD BE THE SCORE\n",
    "\n",
    "Article : {statement}\n",
    "\"\"\"\n",
    "\n",
    "#forming prompt using Langchain PromptTemplate functionality\n",
    "prompt_2 = PromptTemplate(template = template_2, input_variables = [\"statement\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain_2 = LLMChain(prompt = prompt_2, llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f79030",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df['content'][2])\n",
    "print('')\n",
    "print('News sentiment: ', llm_chain_2.run(new_df['content'][2]))\n",
    "# 先对 new_df 第3条新闻内容（索引2）调用 llm_chain_2.run()，获取它的情感分析结果并打印出来。\n",
    "\n",
    "x = []\n",
    "for i in range(0,new_df.shape[0]):\n",
    "    x.append(llm_chain_2.run(new_df['content'][i]))\n",
    "\n",
    "\"\"\"\n",
    "遍历 new_df 的所有行（新闻文本），对每条新闻内容调用 llm_chain_2.run() 进行情感分析，将结果依次追加到列表 x 中。\n",
    "x 最终是一个包含每条新闻情感分析结果的列表。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dt = pd.DataFrame(x) #Converting into Dataframe\n",
    "\"\"\"\n",
    "将结果列表 x 转成一个 DataFrame，方便后续统计和绘图。\n",
    "假设每条情感结果是一个字符串或类别，DataFrame会是单列。\n",
    "\"\"\"\n",
    "\n",
    "column_name = 0 # this is my column name you should change it according to your data\n",
    "value_counts = dt[column_name].value_counts()\n",
    "\"\"\"\n",
    "选 DataFrame 的某一列（这里是第0列），计算每个不同值出现的次数（频率）。\n",
    "value_counts 是一个 Series，索引是不同情感结果，值是出现次数。\n",
    "\"\"\"\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.pie(value_counts, labels = value_counts.index, autopct = '%1.1f%%', startangle = 140)\n",
    "plt.title(f'Pie Chart')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.\n",
    "\"\"\"\n",
    "用 Matplotlib 绘制饼图：\n",
    "value_counts 作为扇区大小\n",
    "value_counts.index 作为扇区标签\n",
    "autopct 显示百分比格式，startangle=140 控制起始角度\n",
    "plt.axis('equal') 保证饼图为正圆形。\n",
    "\"\"\"\n",
    "\n",
    "# Show the pie chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbd75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_to_remove = '0'\n",
    "# Remove all rows where the specified value occurs in the column\n",
    "dt_new = dt[dt[0] != value_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = dt_new[column_name].value_counts()\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.pie(value_counts, labels = value_counts.index, autopct = '%1.1f%%', startangle = 140)\n",
    "plt.title(f'Pie Chart')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.\n",
    "\n",
    "# Show the pie chart\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "这段代码是在原来基础上做了 过滤和重新绘制饼图，作用是：\n",
    "去掉情感为中性（值为 '0'）的新闻，只分析积极和消极的情绪分布，然后画一个饼图展示。\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qwen-Py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
